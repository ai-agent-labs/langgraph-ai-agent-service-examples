import streamlit as st
from qa_chatbot.chain import create_qa_chain, stream_qa


def render():
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "ch03_chain" not in st.session_state:
        with st.spinner("ì±—ë´‡ ì´ˆê¸°í™” ì¤‘..."):
            st.session_state.ch03_chain = create_qa_chain()

    if "ch03_messages" not in st.session_state:
        st.session_state.ch03_messages = []

    # ì‚¬ì´ë“œë°” ì •ë³´
    with st.sidebar:
        st.markdown("""
        ### LCEL íŒŒì´í”„ë¼ì¸
        ```python
        chain = prompt | model | output_parser
        ```

        **ì£¼ìš” ê¸°ëŠ¥:**
        - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
        - `.invoke()` / `.stream()` ë©”ì„œë“œ
        """)

        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", key="ch03_clear"):
            st.session_state.ch03_messages = []
            st.rerun()

    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.ch03_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="ch03_input"):
        st.session_state.ch03_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            full_response = ""

            try:
                for chunk in stream_qa(prompt, st.session_state.ch03_chain):
                    full_response += chunk
                    response_placeholder.markdown(full_response + "â–Œ")

                response_placeholder.markdown(full_response)
                st.session_state.ch03_messages.append(
                    {"role": "assistant", "content": full_response}
                )

            except Exception as e:
                error_message = f"ì˜¤ë¥˜: {str(e)}"
                response_placeholder.error(error_message)
